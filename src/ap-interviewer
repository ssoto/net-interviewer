#!/usr/bin/env python
# -*- coding: utf-8 -*-

import argparse
import time
import json
import os
from pprint import pprint
from snmp.table import Snmp_table_request
import sys

from logstash.udp import Sender
from utils.ip_manager import get_decimal_ip
from utils.color_print import error, success

import logging
logging.basicConfig( format='%(asctime)s - %(pathname)s:%(lineno)d : %(levelname)s  : %(message)s', 
                     level=logging.DEBUG)


def parse_args():

    parser = argparse.ArgumentParser()

    parser.add_argument('-p', '--port', dest='port',
                        default='161', action='store',
                        help='port to send snmp command')

    parser.add_argument('-s', '--server', dest='server', required=True,
                        help='server to send snmp command')

    parser.add_argument('-c', '--community', dest='community', required=True,
                        help='snmp community field')

    parser.add_argument('-sv', '--snmpversion', dest='snmp_version', 
                        default='2c', help='snmp version')

    parser.add_argument('-m', '--mib-name', dest='mib_name', required=True,
                        help='mib name')

    parser.add_argument('-o', '--oids', required=True,
                        type=str, nargs='+',
                        dest='oids',  help='list of oids')

    parser.add_argument('-w', '--write_output', dest='file_name', 
                        help='if passed, snmp output are writed on the file')

    parser.add_argument('-ls', '--ls-host', dest='logstash_host',
                        type=str, help='logstash address to send output')

    parser.add_argument('-lgp', '--ls-port', dest='logstash_port',
                        type=int, help='UDP port of logstash to send json message')

    parser.add_argument('-i', '--interval', dest='seconds_interval', 
                        type=int, default=60, 
                        help="time between polling")

    parser.add_argument('-t', '--timestamp_field', dest='timestamp_field_name', 
                        type=str, default="logTimestamp", 
                        help="time between polling")

    parser.add_argument('-f', '--config_file', dest='config_file_path', 
                        type=str, default="./net_interviewer.conf", 
                        help="path of the configuration file")

    args_parsed = parser.parse_args()

    logging.debug('options passed to the application: %s' % args_parsed)

        
    if hasattr(args_parsed, 'logstash_host') and args_parsed.logstash_host:
        if not hasattr(args_parsed, 'logstash_port') and args_parsed.logstash_port: 
            error("Logstash host and port are needed")
            sys.exit(0)

    return args_parsed

def append_field_from_ds(data, original_ds, destination_ds, field_list):
    """
    Try add a new field on destination_ds for each element in 
    destination_ds with same key. 

    >>> print data
    data  = {
        original_ds : {
            key_a : {
                target_field: value1,
                target_field_2: value2,
                ...
            }
        },
        destination_ds : {
            key_a : {
                ...
            }
        } 
    }
    >>> append_field_from_ds (data, "original_ds", "destination_ds", ["target_field", "target_field_2"] ) 
    >>> print data
    data  = {
        original_ds : {
            key_a : {
                target_field_1: value1,
                target_field_2: value2,
                ...
            }
        },
        destination_ds : {
            key_a : {
                target_field_1: value1,
                target_field_2: value2,
                ...
            }
        } 
    }

    """

    for field in field_list: 
        for ident in data[destination_ds].keys():
            try :
                value_from_original = data[original_ds][ident][field]
                data[destination_ds][ident][field] = value_from_original
            except  KeyError as error:
                logging.debug("element with identier " + ident + " not present in original set" )

def append_field(field_name, field_value, destination_ds):
    """
    Append to destination_ds dictionary the new field and value:
    >>> print destination_ds
    {'key1': 1, 'key2': 2}
    >>> append_field('new_key', 23, destination_ds)
    {'key1': 1, 'key2': 2, 'new_key': 23}
    }
    """
    for ident in destination_ds:
        destination_ds[ident][field_name] = field_value

def write_on_file (file_name, object_data):

        logging.debug("Writting the output to " + file_name)
        try: 
            with open(file_name, 'a') as outfile:
                json.dump(object_data, outfile, indent=2)
        except IOError as e:
            error("Error with file to write request output: " + file_name)
            sys.exit(0)



if __name__ == '__main__':

    args = parse_args()

    if hasattr(args, 'logstash_host') and args.logstash_host and \
        hasattr(args,'logstash_port') and args.logstash_port:    
        udp_sender = Sender( server=args.logstash_host, 
                         port=args.logstash_port)
    else:
        udp_sender = None
    
    # get arguments object

    while True:
        data_dict = { }

        # get all OIDs dicts
        for oid in args.oids:

            OID_req = Snmp_table_request( server = args.server, 
                                          community = args.community, 
                                          snmp_version = args.snmp_version,
                                          port = args.port,
                                          mib_name = args.mib_name, 
                                          oid_name = oid)
            try:
                OID_req.request()
            except Exception as excep:
                logging.error("Error on request " + args.mib_name + '::' + oid)
                logging.error(repr(excep))
                break
            table_dict = OID_req.get_json_reply(args.timestamp_field_name)
            
            # special case, change IpAddress from Hexadecimal
            if oid == 'cDot11ClientConfigInfoTable':
                for index in table_dict:
                    element = table_dict[index]
                    element['IpAddress'] = get_decimal_ip(element['IpAddress'])
            

            mib_oid_name = args.mib_name+"::"+oid 
            # add new key/field to the data_dictionary with the current OID
            data_dict[mib_oid_name] = table_dict

        # add fields from cDot11ClientConfigInfoTable to cDot11ClientStatisticTable
        append_field_from_ds(data=data_dict, 
                             original_ds='CISCO-DOT11-ASSOCIATION-MIB::cDot11ClientConfigInfoTable',
                             destination_ds='CISCO-DOT11-ASSOCIATION-MIB::cDot11ClientStatisticTable',
                             field_list=['IpAddress', 'AssociationState', 'ParentAddress', 'VlanId', ])

        # add access point ip address 
        append_field( field_name="ApAddress", 
                      field_value=args.server, 
                      destination_ds = data_dict['CISCO-DOT11-ASSOCIATION-MIB::cDot11ClientStatisticTable'])
        
        if hasattr(args, 'file_name') and args.file_name:
            write_on_file( file_name=args.file_name, 
                           object_data = data_dict["CISCO-DOT11-ASSOCIATION-MIB::cDot11ClientStatisticTable"])
            success("Request done successfully, output json writed on " + args.file_name)

        if  udp_sender:
            udp_sender.send_dict_values(dict_2_send=data_dict["CISCO-DOT11-ASSOCIATION-MIB::cDot11ClientStatisticTable"],
                                register_fields=['PacketsSent','PacketsReceived', 'BytesSent', 'BytesReceived'],
                                timestamp_field=args.timestamp_field_name)

        # sleep during a few seconds!
        time.sleep(args.seconds_interval)